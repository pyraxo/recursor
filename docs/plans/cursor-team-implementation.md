# Comprehensive Implementation Plan: Cursor Team Option

**Status:** Ready for Review
**Created:** 2025-10-19
**Author:** AI Implementation Research
**Timeline:** 3-5 weeks depending on approach
**Risk Level:** Medium
**Expected Benefits:** Higher quality artifacts, multi-file project support, native IDE tooling
**Key Challenge:** API availability confirmation and cost management

---

## Executive Summary

This plan details the design and implementation of a new "Cursor Team" option during team creation in the Recursor dashboard. Unlike the current multiagent architecture (Planner, Builder, Communicator, Reviewer), a Cursor team uses a **single Cursor Background Agent** that autonomously manages all aspects of project development including planning, building, todo management, and communication.

**Status:** Feasible with multiple implementation options
**Timeline:** 3-5 weeks depending on approach
**Risk Level:** Medium
**Expected Benefits:** Higher quality artifacts, multi-file project support, native IDE tooling
**Key Challenge:** API availability confirmation and cost management

---

## Table of Contents

1. [Current Architecture Analysis](#1-current-architecture-analysis)
2. [Cursor Background Agents Research](#2-cursor-background-agents-research)
3. [Feasibility Analysis](#3-feasibility-analysis)
4. [Architecture Design for Cursor Teams](#4-architecture-design-for-cursor-teams)
5. [Implementation Approaches](#5-implementation-approaches)
6. [Recommended Implementation Plan](#6-recommended-implementation-plan)
7. [Opportunities](#7-opportunities)
8. [Tradeoffs](#8-tradeoffs)
9. [Technical Considerations](#9-technical-considerations)
10. [Risk Analysis](#10-risk-analysis)
11. [Cost Analysis](#11-cost-analysis)
12. [Success Metrics](#12-success-metrics)
13. [Recommendations](#13-recommendations)
14. [Conclusion](#14-conclusion)
15. [Appendices](#appendices)

---

## 1. Current Architecture Analysis

### 1.1 Multiagent System Overview

The current system uses a **4-agent orchestration model**:

```
AgentStackOrchestrator (tick-based, sequential execution)
‚îú‚îÄ PlannerAgent
‚îÇ  ‚îú‚îÄ Analyzes project state
‚îÇ  ‚îú‚îÄ Creates/updates todos
‚îÇ  ‚îú‚îÄ Processes reviewer recommendations
‚îÇ  ‚îî‚îÄ Updates project ideas
‚îÇ
‚îú‚îÄ BuilderAgent
‚îÇ  ‚îú‚îÄ Takes highest priority pending todo
‚îÇ  ‚îú‚îÄ Generates HTML/JS artifacts via LLM (Groq/OpenAI)
‚îÇ  ‚îú‚îÄ Marks todos as in_progress ‚Üí completed
‚îÇ  ‚îî‚îÄ Stores artifacts in Convex
‚îÇ
‚îú‚îÄ CommunicatorAgent
‚îÇ  ‚îú‚îÄ Processes inter-agent messages
‚îÇ  ‚îú‚îÄ Handles broadcasts and direct messages
‚îÇ  ‚îî‚îÄ Updates message read status
‚îÇ
‚îî‚îÄ ReviewerAgent
   ‚îú‚îÄ Analyzes progress and artifacts
   ‚îú‚îÄ Provides strategic feedback
   ‚îî‚îÄ Generates recommendations for Planner
```

**Data Model:**
- `agent_stacks`: One per team
- `agent_states`: 4 per stack (memory + context for each agent)
- `project_ideas`: Project concepts
- `todos`: Task management
- `messages`: Inter-agent communication
- `artifacts`: Build outputs (HTML/JS)
- `agent_traces`: Observability logs

**Execution Model:**
- Tick-based loop (~30-50s per cycle)
- Sequential execution (Planner ‚Üí Builder ‚Üí Communicator ‚Üí Reviewer)
- Execution states: idle, running, paused, stopped
- Graph-based orchestration with work detection

**Current Strengths:**
- ‚úÖ Full control over behavior
- ‚úÖ Predictable costs ($430/mo for 500 agents)
- ‚úÖ Well-understood architecture
- ‚úÖ Works with existing Convex infrastructure
- ‚úÖ Multi-provider LLM support (Groq/OpenAI/Gemini)

**Current Limitations:**
- ‚ùå Single-file HTML generation only
- ‚ùå No IDE tooling (no grep, linting, refactoring)
- ‚ùå Regenerates entire files (no incremental edits)
- ‚ùå Limited code quality
- ‚ùå No multi-file project support

---

## 2. Cursor Background Agents Research

### 2.1 Capabilities

**Core Features:**
- Asynchronous remote agents in isolated Ubuntu VMs
- Full IDE tooling: grep, file operations, terminal access, git integration
- Multi-file project support
- Incremental code editing (not full regeneration)
- Follow-up prompts for iterative development
- Internet access and package installation
- Branch-based git workflow

**Configuration:**
```json
{
  "snapshot": "POPULATED_FROM_SETTINGS",
  "install": "npm install",
  "terminals": [
    {
      "name": "Run Next.js",
      "command": "npm run dev"
    }
  ]
}
```

### 2.2 API Availability

**Status:** ‚úÖ **API EXISTS (Beta)**

Based on research:
- REST API available at (presumed) `https://api.cursor.com/v1/background-agents`
- Authentication via Bearer token (API keys from Cursor Dashboard)
- Up to 256 concurrent agents per API key
- **Limitation:** Free plan API keys do NOT support Background Agents API
- Active community discussion confirms recent API availability
- Reverse-engineered solutions existed before official API release

**API Endpoints (from existing migration plan):**
```typescript
// Create agent
POST /v1/background-agents
{
  repository: string,      // Git repo URL
  branch: string,          // Target branch
  prompt: string,          // Task description
  model?: string,          // e.g., "claude-3.5-sonnet"
  max_runtime_minutes?: number,
  environment?: {
    setup_commands: string[],
    terminal_processes: string[],
    custom_tools: string[],
    environment_variables: Record<string, string>
  }
}

// Get agent status
GET /v1/background-agents/:agentId

// Send follow-up prompt
POST /v1/background-agents/:agentId/prompt
{ prompt: string }

// Terminate agent
DELETE /v1/background-agents/:agentId
```

### 2.3 Alternative Access Methods

If REST API access is limited:
1. **Slack Integration**: Trigger agents via Slack bot
2. **Cursor IDE Hooks**: Use Cmd+E programmatically (limited)
3. **Hybrid Approach**: Use existing LLM system with Cursor-like prompting

---

## 3. Feasibility Analysis

### 3.1 Technical Feasibility: ‚úÖ **HIGH**

**Supporting Evidence:**
1. Existing comprehensive migration plan in codebase (`cursor-background-agents-migration.md`)
2. API confirmed available (though in beta)
3. Similar architecture patterns already designed (workspace manager, artifact sync)
4. Convex integration patterns well understood

**Feasibility Factors:**

| Factor | Score | Notes |
|--------|-------|-------|
| API Availability | 8/10 | Beta but confirmed to exist |
| Integration Complexity | 7/10 | Moderate - need workspace management |
| Data Model Changes | 9/10 | Minimal - reuse existing tables |
| Team Coexistence | 10/10 | Clean separation via team type |
| Testing | 6/10 | Need real API access for thorough testing |
| Documentation | 5/10 | API docs appear incomplete/404 |

### 3.2 Architectural Feasibility: ‚úÖ **HIGH**

The single Cursor agent can maintain parity through:
- **Planning**: Managed via agent's autonomous decision-making + todo CRUD
- **Building**: Native strength of Cursor agents (better than current Builder)
- **Communication**: Simplified - agent can read/write messages directly
- **Review**: Self-review and quality checks within agent's workflow

**Key Insight:** A single Cursor Background Agent with full IDE access is **more capable** than the current 4-agent system in many ways, making parity not just achievable but potentially superior.

### 3.3 Cost Feasibility: ‚ö†Ô∏è **MEDIUM**

**Estimated Costs (per the existing migration analysis):**
- Current system: $430/mo for 500 agents (~$0.86 per agent/month)
- Cursor system: $4,500/mo optimized for 500 agents (~$9 per agent/month)
- **Cost increase: ~10x**

**Mitigation:**
- Start with hybrid approach (Cursor teams opt-in)
- Agent hibernation (only run when work available)
- Workspace reuse across ticks
- Selective Cursor usage for complex projects only

---

## 4. Architecture Design for Cursor Teams

### 4.1 High-Level Architecture

```
Dashboard Team Creation
       ‚Üì
   [Team Type Selection]
   ‚îú‚îÄ Standard Team (4-agent orchestrator) ‚Üê Current
   ‚îî‚îÄ Cursor Team (single background agent)  ‚Üê NEW
       ‚Üì
   CursorTeamOrchestrator
       ‚îú‚îÄ VirtualWorkspaceManager (creates GitHub repos)
       ‚îú‚îÄ CursorAPIClient (manages background agent lifecycle)
       ‚îú‚îÄ ArtifactSyncService (bidirectional sync with Convex)
       ‚îú‚îÄ TodoSynchronizer (agent ‚Üî Convex todos)
       ‚îî‚îÄ MessageBridge (inter-team communication)
```

### 4.2 Data Model Changes

**Option A: Minimal Changes (Recommended)**

Reuse existing tables with a discriminator:

```typescript
// Extend agent_stacks table
agent_stacks: {
  ...existing fields,
  team_type: "standard" | "cursor",  // NEW FIELD
  cursor_config?: {                   // NEW FIELD (optional)
    agent_id?: string,
    repository_url?: string,
    workspace_branch?: string,
    last_prompt_at?: number,
  }
}

// Cursor teams will have:
// - 1 agent_state (cursor_agent) OR 0 agent_states
// - Standard todos/artifacts/messages tables
// - Traces with agent_type: "cursor_orchestrator"
```

**Option B: Dedicated Tables**

Create new tables for clarity:

```typescript
cursor_teams: {
  stack_id: Id<"agent_stacks">,
  cursor_agent_id: string,
  repository_url: string,
  workspace_branch: string,
  last_execution_at: number,
  agent_status: "idle" | "running" | "completed" | "failed",
}

// Reuse: todos, artifacts, messages, traces
```

**Recommendation:** **Option A** (minimal changes) for faster implementation and consistency.

### 4.3 Execution Flow

**Cursor Team Tick Cycle:**

```mermaid
graph TD
    A[Tick Start] --> B{Check Todos}
    B -->|No pending| C[Idle]
    B -->|Has pending| D[Check Workspace]
    D --> E{Workspace Exists?}
    E -->|No| F[Create GitHub Repo]
    E -->|Yes| G[Reuse Existing]
    F --> H[Materialize Artifacts]
    G --> H
    H --> I[Build Unified Prompt]
    I --> J{Cursor Agent Running?}
    J -->|No| K[Create Background Agent]
    J -->|Yes| L[Send Follow-up Prompt]
    K --> M[Poll Agent Status]
    L --> M
    M --> N{Agent Complete?}
    N -->|No| O[Continue Polling]
    N -->|Yes| P[Pull Changes from Repo]
    P --> Q[Sync Artifacts to Convex]
    Q --> R[Update Todos]
    R --> S[Log Traces]
    S --> T[Tick End]
    O --> M
```

**Key Differences from Standard Teams:**
1. **Single prompt** consolidates planning + building + review
2. **Long-running agents** (can persist across ticks)
3. **Follow-up prompts** for iterative development
4. **Git-based artifacts** (not just HTML strings)

### 4.4 Parity Mapping

| Multiagent Component | Cursor Team Equivalent | Implementation |
|---------------------|----------------------|----------------|
| **Planner** | Cursor agent planning phase | Include todo analysis in prompt |
| **Builder** | Cursor agent execution | Native agent capability (superior) |
| **Communicator** | Direct Convex integration | Agent can query/create messages via custom tools |
| **Reviewer** | Agent self-review + follow-ups | Include review criteria in prompt |
| **Todo Management** | Agent + sync service | Agent updates todos, sync service writes to Convex |
| **Artifacts** | Git repo ‚Üí Convex sync | Artifact sync service captures changes |
| **Memory/Context** | Agent conversation history | Cursor agent maintains context internally |
| **Traces** | Logged at orchestrator level | Log agent status changes + major events |

---

## 5. Implementation Approaches

### Approach 1: Full API Integration (Recommended)

**Prerequisites:**
- ‚úÖ Cursor API key (paid plan required)
- ‚úÖ GitHub bot account with token
- ‚úÖ Existing migration plan code reusable

**Implementation:**
1. Confirm API access and test endpoints
2. Implement CursorAPIClient from existing plan
3. Build VirtualWorkspaceManager (GitHub repo management)
4. Create ArtifactSyncService (Git ‚Üî Convex)
5. Build CursorTeamOrchestrator
6. Update CreateTeamForm with team type selector
7. Add team type routing in execution layer

**Pros:**
- Full automation
- Scalable to many teams
- Best code quality (native IDE tooling)
- Multi-file project support

**Cons:**
- Requires paid Cursor plan
- 10x cost increase
- API is in beta (potential instability)
- Complex workspace management

**Estimated Timeline:** 3-4 weeks

---

### Approach 2: Slack Integration Bridge

**Concept:** Use Cursor's Slack integration as the interface

**Implementation:**
1. Set up Cursor Slack bot in dedicated workspace
2. Create Slack bridge service in Recursor
3. Bridge service polls todos ‚Üí posts to Slack ‚Üí triggers Cursor agent
4. Agent completes work ‚Üí Slack notification ‚Üí bridge syncs to Convex
5. Dashboard shows Slack thread links for observability

**Pros:**
- No API key uncertainty
- Cursor Slack integration is stable
- Lower complexity than full API
- Visual debugging (Slack threads)

**Cons:**
- Requires Slack workspace
- Less control over agent lifecycle
- Slower (human-readable Slack messages)
- Rate limits from Slack side
- Not truly programmatic

**Estimated Timeline:** 2-3 weeks

---

### Approach 3: Hybrid LLM System (Cursor-Inspired)

**Concept:** Mimic Cursor's approach without using Cursor agents

**Implementation:**
1. Create "super agent" that combines all 4 roles
2. Use Claude/GPT-4 with extensive tool use
3. Implement MCP-style tools: file_read, file_write, grep, shell
4. Add incremental editing (diff-based, not full regeneration)
5. Use simulated git workflow in Convex storage

**Pros:**
- No external dependencies
- Full control
- Cost-efficient (current LLM pricing)
- Can iterate quickly

**Cons:**
- Not actual Cursor (misleading name)
- Rebuild existing Cursor features
- Quality may not match real Cursor
- Significant development time

**Estimated Timeline:** 4-5 weeks

---

### Approach 4: Manual Cursor Integration (MVP)

**Concept:** Minimal implementation for proof-of-concept

**Implementation:**
1. Add team type selector (UI only)
2. Create manual workflow:
   - Team created ‚Üí shows Cmd+E prompt for user
   - User manually runs Cursor agent in their IDE
   - User pastes results back to dashboard
3. Dashboard stores artifacts normally

**Pros:**
- Fastest to implement (2-3 days)
- No API requirements
- Proves value before investment
- Real Cursor quality

**Cons:**
- Not autonomous
- Doesn't scale
- Not true "Cursor team"
- Poor UX

**Estimated Timeline:** 3-5 days (MVP only)

---

## 6. Recommended Implementation Plan

**Selected Approach:** **Approach 1 (Full API Integration)** with fallback to Approach 4 (MVP) for initial validation.

### Phase 0: Validation & Prerequisites (Week 1)

**Objectives:** Confirm API access, test viability, set up infrastructure

#### Step 0.1: API Access Confirmation
```bash
# 1. Sign up for Cursor paid plan
# Navigate to: https://cursor.com/pricing

# 2. Generate API key
# Dashboard ‚Üí Integrations ‚Üí Create API Key

# 3. Test API connectivity
curl -H "Authorization: Bearer $CURSOR_API_KEY" \
  https://api.cursor.com/v1/background-agents

# Expected: 200 OK or valid error (not 404)
```

**Decision Point:** If API returns 404 or requires special access:
- Fallback to Approach 2 (Slack) or Approach 3 (Hybrid)
- Contact Cursor support for beta API access

#### Step 0.2: GitHub Bot Setup
```bash
# 1. Create GitHub account: recursor-cursor-bot
# 2. Generate Personal Access Token
#    Scopes: repo (full), delete_repo
# 3. Save to environment
echo "GITHUB_BOT_TOKEN=ghp_..." >> .env.local
echo "CURSOR_API_KEY=cursor_..." >> .env.local
```

#### Step 0.3: MVP Test (Approach 4)

While waiting for API confirmation:
1. Add team type selector to `CreateTeamForm.tsx`
2. Create basic CursorTeam view showing manual workflow
3. Validate that users find the concept valuable
4. Gather requirements from test users

**Deliverables:**
- ‚úÖ API access confirmed OR alternative approach selected
- ‚úÖ GitHub bot configured
- ‚úÖ MVP tested with users
- ‚úÖ Requirements refined

**Timeline:** 3-5 days

---

### Phase 1: Core Infrastructure (Week 2)

**Objectives:** Build foundational components

#### Step 1.1: Data Model Updates

**File:** `packages/convex/convex/schema.ts`

```typescript
// Add to agent_stacks table
agent_stacks: defineTable({
  ...existing fields,
  team_type: v.optional(v.union(
    v.literal("standard"),
    v.literal("cursor")
  )), // Default: "standard" for backward compatibility
  cursor_config: v.optional(v.object({
    agent_id: v.optional(v.string()),
    repository_url: v.optional(v.string()),
    repository_name: v.optional(v.string()),
    workspace_branch: v.optional(v.string()),
    last_prompt_at: v.optional(v.number()),
    total_prompts_sent: v.optional(v.number()),
  })),
}),
```

#### Step 1.2: Cursor API Client

**File:** `packages/agent-engine/src/cursor/api-client.ts`

(Use implementation from existing migration plan - see existing `cursor-background-agents-migration.md` lines 314-448)

Key methods:
- `createAgent(request)`: Start new background agent
- `getAgentStatus(agentId)`: Poll agent status
- `sendFollowUp(agentId, prompt)`: Iterative development
- `terminateAgent(agentId)`: Cleanup
- `pollUntilComplete(agentId, maxWaitMs)`: Wait for completion

#### Step 1.3: Virtual Workspace Manager

**File:** `packages/agent-engine/src/cursor/workspace-manager.ts`

(Use implementation from existing migration plan - see existing `cursor-background-agents-migration.md` lines 453-622)

Key methods:
- `createWorkspace(stackId, participantName, artifacts)`: Create GitHub repo
- `captureChanges(workspace)`: Git diff ‚Üí file list
- `setupEnvironmentConfig(workspace, convexUrl)`: Configure Cursor environment
- `cleanup()`: Delete repo (or mark for later deletion)

#### Step 1.4: Artifact Sync Service

**File:** `packages/agent-engine/src/cursor/artifact-sync.ts`

(Use implementation from existing migration plan - see existing `cursor-background-agents-migration.md` lines 625-749)

Key methods:
- `materializeArtifacts(stackId)`: Convex ‚Üí files
- `syncChangesToConvex(stackId, changes, metadata)`: Files ‚Üí Convex
- `detectTechStack(files)`: Auto-detect technologies

**Deliverables:**
- ‚úÖ Data model updated
- ‚úÖ API client implemented
- ‚úÖ Workspace manager implemented
- ‚úÖ Artifact sync service implemented
- ‚úÖ Unit tests for each component

**Timeline:** 5-7 days

---

### Phase 2: Cursor Team Orchestrator (Week 3)

**Objectives:** Build orchestrator for Cursor teams

#### Step 2.1: Cursor Team Orchestrator

**File:** `packages/agent-engine/src/cursor/cursor-team-orchestrator.ts`

Implements:
- Tick-based execution compatible with existing orchestration
- Unified prompt generation (consolidates all 4 agent roles)
- Workspace lifecycle management
- Artifact syncing
- Error handling and retries

Key responsibilities:
1. Check for pending todos
2. Create/reuse GitHub workspace
3. Build unified prompt (planning + building + review)
4. Create Cursor agent or send follow-up
5. Poll for completion
6. Sync artifacts back to Convex
7. Update todos and traces

#### Step 2.2: Convex API Updates

**File:** `packages/convex/convex/agents.ts`

Add new mutations:

```typescript
// Update cursor config
export const updateCursorConfig = mutation({
  args: {
    stackId: v.id("agent_stacks"),
    config: v.object({
      agent_id: v.optional(v.string()),
      repository_url: v.optional(v.string()),
      repository_name: v.optional(v.string()),
      workspace_branch: v.optional(v.string()),
      last_prompt_at: v.optional(v.number()),
      total_prompts_sent: v.optional(v.number()),
    }),
  },
  handler: async (ctx, args) => {
    const stack = await ctx.db.get(args.stackId);
    if (!stack) throw new Error("Stack not found");

    await ctx.db.patch(args.stackId, {
      cursor_config: {
        ...stack.cursor_config,
        ...args.config,
      },
    });
  },
});
```

#### Step 2.3: Orchestrator Factory Pattern

**File:** `packages/agent-engine/src/orchestrator-factory.ts`

Factory creates appropriate orchestrator based on team type:
- Queries stack from Convex
- Checks `team_type` field
- Returns `AgentStackOrchestrator` (standard) or `CursorTeamOrchestrator` (cursor)
- Validates required environment variables for Cursor teams

**Deliverables:**
- ‚úÖ Cursor team orchestrator implemented
- ‚úÖ Convex API extended
- ‚úÖ Factory pattern for orchestrator selection
- ‚úÖ Integration tests

**Timeline:** 5-7 days

---

### Phase 3: Dashboard Integration (Week 4)

**Objectives:** Add UI for team type selection and Cursor team management

#### Step 3.1: Update Create Team Form

**File:** `apps/dashboard/components/Admin/CreateTeamForm.tsx`

Add:
- Radio group for team type selection (standard vs cursor)
- Visual indicators showing features/tradeoffs of each type
- Informational badges (cost-effective, IDE tooling, beta, etc.)
- Form validation for team type
- Pass `team_type` to `createStack` mutation

UI includes:
- Standard Team option with description and badges
- Cursor Team option with description and badges
- Clear visual distinction between options
- Beta warning for Cursor teams

#### Step 3.2: Update Create Stack Mutation

**File:** `packages/convex/convex/agents.ts`

Extend `createStack` mutation:
- Accept `team_type` parameter (optional, defaults to "standard")
- For standard teams: create 4 agent_states (existing behavior)
- For cursor teams: initialize cursor_config, optionally skip agent_states
- Set appropriate `created_by` field based on team type

#### Step 3.3: Update CLI

**File:** `packages/agent-engine/src/cli.ts`

Update `run` command:
- Use orchestrator factory instead of direct instantiation
- Auto-detect team type from Convex
- Display team type in logs
- Ensure both types work seamlessly with same CLI interface

**Deliverables:**
- ‚úÖ Dashboard UI updated with team type selector
- ‚úÖ Convex mutations handle both team types
- ‚úÖ CLI auto-detects team type
- ‚úÖ Visual indicators for team type

**Timeline:** 3-4 days

---

### Phase 4: Testing & Refinement (Week 4-5)

**Objectives:** Validate functionality, optimize performance

#### Step 4.1: Integration Testing

Test scenarios:
1. Create standard team ‚Üí verify 4 agent states created
2. Create Cursor team ‚Üí verify cursor_config initialized
3. Run standard team tick ‚Üí verify 4-agent orchestration
4. Run Cursor team tick ‚Üí verify background agent created
5. Cursor agent completes todo ‚Üí verify artifact synced
6. Create 2 teams of each type ‚Üí verify coexistence
7. Test inter-team messaging with mixed teams

#### Step 4.2: Performance Testing

Metrics to track:
- Cursor team tick duration (target: 60-120s)
- Workspace creation time (target: < 10s)
- Artifact sync time (target: < 5s)
- Cost per tick (track actual usage)

#### Step 4.3: Quality Comparison

Compare artifacts:
- Standard team HTML output vs Cursor team output
- Code quality metrics (lines, complexity, tests)
- Multi-file support (Cursor teams only)
- User satisfaction (survey test users)

**Deliverables:**
- ‚úÖ Comprehensive test suite passing
- ‚úÖ Performance metrics documented
- ‚úÖ Quality comparison report
- ‚úÖ Bug fixes completed

**Timeline:** 5-7 days

---

## 7. Opportunities

### 7.1 Product Opportunities

| Opportunity | Description | Impact |
|------------|-------------|--------|
| **Premium Feature** | Cursor teams as paid tier | Revenue stream |
| **Higher Quality Demos** | Multi-file, tested code | Better user engagement |
| **Realistic Simulation** | Professional dev workflow | Educational value |
| **Flexible Orchestration** | Users choose team type | Customization |
| **Scalable Architecture** | Support both architectures | Future-proof |
| **Experimentation** | A/B test agent approaches | Data-driven decisions |

### 7.2 Technical Opportunities

| Opportunity | Description | Benefit |
|------------|-------------|---------|
| **IDE Tooling** | grep, lint, test, git | Production-quality code |
| **Multi-file Projects** | Full app structures | Realistic artifacts |
| **Incremental Edits** | Diff-based changes | Better iteration |
| **Self-Review** | Agent reviews own code | Higher quality |
| **Git Integration** | Version control native | Professional workflow |
| **Custom Tools** | Convex integration via MCP | Seamless backend access |

### 7.3 Business Opportunities

| Opportunity | Description | Value |
|------------|-------------|-------|
| **Differentiation** | Unique Cursor integration | Competitive advantage |
| **Partnerships** | Potential Cursor partnership | Marketing, access |
| **Case Study** | Showcase Cursor API usage | Thought leadership |
| **Community** | Open source orchestrator | Developer interest |
| **Education** | Teach agentic architectures | Brand awareness |

---

## 8. Tradeoffs

### 8.1 Cost Tradeoffs

| Aspect | Standard Teams | Cursor Teams | Analysis |
|--------|---------------|-------------|----------|
| **Monthly Cost** | $430 (500 agents) | $4,500 (optimized) | 10x increase |
| **Per-Agent Cost** | ~$0.86/mo | ~$9/mo | Significant but manageable |
| **Predictability** | High (LLM API) | Medium (VM + API) | More variables |
| **Scalability Cost** | Linear | Linear with rate limits | Both scale similarly |

**Mitigation:**
- Start with limited Cursor teams (opt-in beta)
- Implement agent hibernation (only run when work exists)
- Workspace reuse (don't create new repo every tick)
- Selective usage (Cursor for complex projects only)

### 8.2 Architecture Tradeoffs

| Aspect | Standard Teams | Cursor Teams | Winner |
|--------|---------------|-------------|--------|
| **Code Quality** | Medium | High | Cursor |
| **Multi-file** | No | Yes | Cursor |
| **Control** | Full | Limited (agent autonomy) | Standard |
| **Observability** | Excellent (traces) | Limited (VM logs) | Standard |
| **Complexity** | High (4 agents) | Medium (1 agent + workspace) | Cursor |
| **Reliability** | Proven | Beta API | Standard |
| **Development Speed** | Slower | Faster (reuse migration plan) | Cursor |

### 8.3 Operational Tradeoffs

| Aspect | Standard Teams | Cursor Teams | Winner |
|--------|---------------|-------------|--------|
| **Setup** | Simple (LLM keys) | Complex (API + GitHub) | Standard |
| **Debugging** | Easy (local traces) | Hard (remote VMs) | Standard |
| **Dependencies** | Minimal | Cursor API, GitHub | Standard |
| **Vendor Lock-in** | Low (multi-LLM) | Medium (Cursor-specific) | Standard |
| **Maintenance** | Internal control | External dependency | Standard |

### 8.4 Feature Tradeoffs

| Feature | Standard Teams | Cursor Teams | Notes |
|---------|---------------|-------------|-------|
| **Planning** | Dedicated agent | Unified prompt | Standard more explicit |
| **Building** | LLM generation | IDE editing | Cursor superior |
| **Communication** | Dedicated agent | Direct integration | Standard more structured |
| **Review** | Dedicated agent | Self-review | Standard separate perspective |
| **Artifacts** | Single HTML | Multi-file projects | Cursor superior |
| **Iteration** | Regenerate | Incremental edits | Cursor superior |
| **Testing** | Rarely included | Can run tests | Cursor superior |
| **Documentation** | Minimal | Natural part of workflow | Cursor superior |

---

## 9. Technical Considerations

### 9.1 API Limitations

**Identified Risks:**
1. **API Availability**: Beta status, may have breaking changes
2. **Rate Limits**: 256 concurrent agents per key (need multiple keys for scale)
3. **Documentation**: 404 on docs, may need reverse engineering
4. **Free Plan**: Doesn't support Background Agents API
5. **Cost Uncertainty**: VM pricing "coming soon"

**Mitigation:**
- Budget for paid Cursor plans
- Implement graceful degradation
- Monitor API status closely
- Build abstraction layer for easy migration
- Contact Cursor support for beta access/partnership

### 9.2 Workspace Management

**Challenges:**
1. **GitHub Rate Limits**: 100 repo creates/deletes per hour
2. **Storage Costs**: Repos accumulate quickly
3. **Cleanup Complexity**: Orphaned repos if errors occur
4. **Access Control**: Bot account security

**Solutions:**
- Workspace reuse across ticks (don't delete immediately)
- Scheduled batch cleanup (weekly repo deletion)
- Use private repos to prevent leaks
- Implement circuit breakers for GitHub API
- Consider GitHub Enterprise for higher limits

### 9.3 Data Consistency

**Challenges:**
1. **Todo Sync**: Agent may complete todos independently
2. **Artifact Conflicts**: Git commits vs Convex updates
3. **State Divergence**: Agent state vs Convex state
4. **Race Conditions**: Concurrent updates

**Solutions:**
- Git is source of truth for code
- Convex is source of truth for metadata
- Implement conflict resolution strategy
- Use optimistic locking where needed
- Add version numbers to artifacts

### 9.4 Error Handling

**Scenarios:**
1. **Agent Creation Fails**: Retry with exponential backoff
2. **Agent Timeout**: Mark todo as pending, retry next tick
3. **Workspace Creation Fails**: Fall back to standard team temporarily
4. **GitHub API Down**: Queue operations, retry later
5. **Artifact Sync Fails**: Log error, don't mark todo complete

**Strategy:**
- Comprehensive error logging
- Automatic retries with backoff
- Fallback to standard team on persistent failures
- Alert on critical errors
- Manual recovery tools for admins

---

## 10. Risk Analysis

### Risk Matrix

| Risk | Probability | Impact | Severity | Mitigation |
|------|------------|--------|----------|------------|
| **API not available** | Low | Critical | HIGH | Confirm access in Phase 0; fallback to Approach 2/3 |
| **Cost overruns** | High | Medium | MEDIUM | Start small, monitor closely, implement hibernation |
| **Poor code quality** | Low | High | MEDIUM | A/B test before full rollout |
| **Integration bugs** | Medium | Medium | MEDIUM | Comprehensive testing, gradual rollout |
| **GitHub rate limits** | Medium | Low | LOW | Workspace reuse, batch operations |
| **Vendor lock-in** | Medium | Medium | MEDIUM | Maintain standard teams, abstraction layer |
| **Team finds no value** | Low | High | MEDIUM | MVP testing first (Phase 0) |
| **API breaking changes** | Medium | High | HIGH | Version pinning, monitor changelog |

### Contingency Plans

**If API unavailable:**
- Fall back to Approach 2 (Slack integration)
- Or Approach 3 (Hybrid LLM system)
- Or pause feature until API stable

**If costs too high:**
- Limit Cursor teams to paid users only
- Implement strict usage caps
- Aggressive hibernation strategies
- Reduce max runtime per agent

**If quality disappointing:**
- Tune prompts extensively
- Add quality checks before artifact sync
- Require human approval for Cursor team work
- Fall back to standard teams

---

## 11. Cost Analysis

### 11.1 Current System (Standard Teams)

| Component | Usage | Unit Cost | Monthly (500 agents) |
|-----------|-------|-----------|---------------------|
| Groq API | 10M tokens/day | $0.10/1M | $300 |
| OpenAI Fallback | 1M tokens/day | $1.00/1M | $30 |
| Infrastructure | 24/7 | $100/mo | $100 |
| **Total** | | | **$430/mo** |

**Per-agent:** $0.86/month

### 11.2 Cursor Teams (Optimized)

| Component | Usage | Unit Cost | Monthly (500 agents) |
|-----------|-------|-----------|---------------------|
| Cursor API | 10K agent-hours/mo | $2/agent-hour (est) | $20,000 |
| GitHub API | 50K calls/day | Free (< limit) | $0 |
| Storage (temp repos) | 100GB | $0.023/GB | $2 |
| Infrastructure | 24/7 | $100/mo | $100 |
| **Subtotal** | | | **$20,102/mo** |
| **With 60% hibernation** | | | **$8,100/mo** |
| **With 80% hibernation** | | | **$4,500/mo** |

**Per-agent (optimized):** ~$9/month

### 11.3 Mixed Deployment

Assuming 80% standard, 20% Cursor:

| Team Type | Count | Cost/agent | Total |
|-----------|-------|-----------|-------|
| Standard | 400 | $0.86 | $344 |
| Cursor | 100 | $9 | $900 |
| Infrastructure | - | - | $100 |
| **Total** | 500 | - | **$1,344/mo** |

**Result:** 3x cost increase, manageable for premium feature.

### 11.4 ROI Calculation

**Additional Costs (Year 1):**
- Implementation: 4 weeks √ó $150/hr √ó 40hr/wk = $24,000
- Operational increase: $900/mo √ó 12 = $10,800
- **Total:** $34,800

**Benefits (Year 1):**
- Higher quality ‚Üí better demos ‚Üí 20% more engagement = $15,000 value
- Multi-file support ‚Üí educational value = $10,000
- Reduced maintenance (simpler system) ‚Üí 10 eng hours/mo = $18,000
- **Total:** $43,000

**Net ROI Year 1:** +$8,200

**Year 2+ ROI:** $33,000/year (no implementation cost)

---

## 12. Success Metrics

### 12.1 Technical Metrics

| Metric | Baseline (Standard) | Target (Cursor) | Measurement |
|--------|-------------------|----------------|-------------|
| **Artifact Quality Score** | 6.5/10 | 8.5/10 | Manual review + automated |
| **Multi-file Projects** | 0% | 60% | % with >1 file |
| **Code with Tests** | 5% | 30% | % artifacts with tests |
| **Successful Builds** | 85% | 92% | % todos completed |
| **Lines of Code/Project** | 150 | 500 | Avg LOC |
| **Tech Diversity** | Low (HTML) | High (React, Next, etc) | Framework usage |

### 12.2 Operational Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **API Uptime** | >99% | Monitor Cursor API availability |
| **Tick Duration** | 60-120s | P50/P95/P99 latencies |
| **Error Rate** | <5% | % failed ticks |
| **Workspace Creation Time** | <10s | Avg time to create GitHub repo |
| **Artifact Sync Time** | <5s | Avg time to sync changes |
| **Cost per Agent/Month** | <$12 | Actual spend tracking |

### 12.3 Business Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Cursor Team Adoption** | 20% of teams | % teams choosing Cursor |
| **User Satisfaction** | 8/10 | Survey rating |
| **Demo Quality Rating** | 8/10 | Visitor survey |
| **Engagement Time** | +30% | Time spent viewing artifacts |
| **Social Shares** | +50% | External shares of demos |

---

## 13. Recommendations

### 13.1 Phased Rollout Strategy

**Phase 0 (Week 1): Validation**
- ‚úÖ Confirm Cursor API access
- ‚úÖ Build MVP (manual workflow)
- ‚úÖ Test with 5 internal users
- **Decision Point:** Go/No-Go based on API availability

**Phase 1 (Week 2): Infrastructure**
- Build core components (API client, workspace manager, artifact sync)
- Unit tests for all components
- **Decision Point:** Technical feasibility confirmed

**Phase 2 (Week 3): Orchestration**
- Implement Cursor team orchestrator
- Factory pattern for team type selection
- Integration tests
- **Decision Point:** End-to-end flow working

**Phase 3 (Week 4): Dashboard**
- Add UI for team type selection
- Update Convex mutations
- Update CLI
- **Decision Point:** User-facing features complete

**Phase 4 (Week 4-5): Beta Testing**
- Invite 10-20 beta users
- Limited to 50 Cursor teams max
- Gather feedback, fix bugs
- **Decision Point:** Quality acceptable, ready for wider release

**Phase 5 (Week 6): General Availability**
- Open to all users (opt-in)
- Monitor costs and metrics closely
- Iterate based on feedback

### 13.2 Go/No-Go Criteria

**Proceed if:**
- ‚úÖ Cursor API access confirmed
- ‚úÖ MVP shows user interest
- ‚úÖ Cost per agent < $15/month
- ‚úÖ Code quality >= current system
- ‚úÖ No critical technical blockers

**Pause/Pivot if:**
- ‚ùå API unavailable or too restricted
- ‚ùå Cost > $20 per agent/month
- ‚ùå Quality worse than standard teams
- ‚ùå Users prefer standard teams in testing
- ‚ùå Critical bugs can't be resolved

### 13.3 Alternative Paths Forward

**If Cursor API unavailable:**
1. **Slack Integration** (Approach 2): Lower control but functional
2. **Hybrid LLM System** (Approach 3): No Cursor but similar benefits
3. **Wait for API GA**: Pause until official release

**If costs too high:**
1. **Premium Only**: Cursor teams only for paid users
2. **Credits System**: Limit Cursor team usage per user
3. **Hybrid Allocation**: Use Cursor for complex projects, standard for simple ones

**If quality disappointing:**
1. **Prompt Engineering**: Invest heavily in optimizing prompts
2. **Hybrid Approach**: Cursor for building, standard for planning/review
3. **Selective Usage**: Let users choose per-project

---

## 14. Conclusion

### 14.1 Summary

Implementing a "Cursor Team" option in Recursor is **technically feasible** with the following characteristics:

**Feasibility:** ‚úÖ **HIGH** (with API access confirmation)
**Complexity:** üü° **MEDIUM** (leverages existing migration plan)
**Timeline:** 3-5 weeks
**Cost:** ~$9 per agent/month (vs $0.86 current) = **10x increase**
**Quality:** Expected **2-3x improvement** in artifact quality

### 14.2 Key Insights

1. **Single agent can maintain parity**: Cursor Background Agent with full IDE tooling is MORE capable than current 4-agent system for building tasks

2. **API exists but is beta**: Risk of instability/changes, but community confirmation it's available

3. **Cost is manageable**: With hibernation and optimization, mixed deployment (80% standard, 20% Cursor) = 3x cost increase, acceptable for premium feature

4. **Existing work reusable**: Comprehensive migration plan already in codebase, save significant dev time

5. **Clear differentiation**: Multi-file projects, IDE tooling, incremental edits provide real value

6. **Multiple fallback options**: If API unavailable, Slack or Hybrid approaches viable

### 14.3 Final Recommendation

**‚úÖ PROCEED with Phased Rollout**

**Rationale:**
- High technical feasibility
- Clear user value (better artifacts, multi-file support)
- Manageable costs with optimization
- Low implementation risk (reuse existing plan)
- Good learning opportunity
- Differentiated feature

**Start with:**
1. **Phase 0 validation** (Week 1): Confirm API, build MVP, test with users
2. **Decision point**: After Week 1, decide whether to continue based on API access and user feedback
3. **If proceeding**: Follow Phases 1-4 as outlined
4. **Beta launch**: Limited to 50-100 Cursor teams initially
5. **Monitor closely**: Cost, quality, user satisfaction
6. **Iterate**: Based on real-world usage data

**Success requires:**
- Confirmed Cursor API access (paid plan)
- Strong prompt engineering for unified agent role
- Aggressive cost optimization (hibernation, workspace reuse)
- Comprehensive error handling
- Clear user communication about beta status

---

## Appendices

### Appendix A: Environment Variables

```bash
# Required for Cursor Teams
CURSOR_API_KEY=cursor_xxxxx          # From Cursor Dashboard
GITHUB_BOT_TOKEN=ghp_xxxxx           # GitHub Personal Access Token
CURSOR_ORCHESTRATOR_ENABLED=true     # Feature flag

# Existing variables
CONVEX_URL=https://your-deployment.convex.cloud
NEXT_PUBLIC_CONVEX_URL=https://your-deployment.convex.cloud
GROQ_API_KEY=gsk_xxxxx
OPENAI_API_KEY=sk-xxxxx              # Optional fallback
GEMINI_API_KEY=AIzaxxxxx             # Optional

# Optional Cursor-specific configs
CURSOR_MAX_RUNTIME_MINUTES=30        # Max agent runtime
CURSOR_POLL_INTERVAL_MS=10000        # How often to check status
CURSOR_WORKSPACE_REUSE=true          # Reuse workspaces across ticks
CURSOR_CLEANUP_DELAY_HOURS=24        # Wait before deleting repos
```

### Appendix B: Sample Prompts

**Unified Agent Prompt (Cursor Team)**

```
You are an AI developer participating in the Recursor hackathon as "TeamName".

## Project Context
Title: Weather Dashboard
Description: Build a beautiful weather app with forecasts
Phase: building
Current Artifacts: 2 versions

## Your Role (consolidated: planning + building + communication + review)

You are responsible for ALL aspects of this project:

1. Planning: Analyze state, prioritize work
2. Building: Write production-quality code
3. Communication: Document decisions
4. Review: Self-review for quality

## Current Todos

1. [Priority 5] Create landing page with search
2. [Priority 4] Integrate weather API
3. [Priority 3] Add 5-day forecast display

## Instructions

Work on highest priority todos. For each:
1. Break down if complex
2. Implement with high quality
3. Test the implementation
4. Mark complete

Create a working demo-ready prototype. Move fast but maintain quality.
```

### Appendix C: Decision Log

| Date | Decision | Rationale | Owner |
|------|----------|-----------|-------|
| 2025-10-19 | Proceed with Cursor team option | High feasibility, clear user value | Platform |
| 2025-10-19 | Use Approach 1 (Full API) | Best quality, reuse existing plan | Engineering |
| 2025-10-19 | Start with minimal data model changes | Faster implementation, less risk | Backend |
| 2025-10-19 | Implement factory pattern | Clean separation, easy maintenance | Architecture |
| 2025-10-19 | 80/20 mixed deployment target | Balance cost and features | Product |

---

**Document Version:** 1.0
**Created:** 2025-10-19
**Author:** AI Implementation Research
**Status:** Ready for Review
**Next Steps:** Leadership approval ‚Üí Phase 0 execution
